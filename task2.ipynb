{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6151805a-09a1-4171-b48c-7c69459fefa0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'my_function_to_test' from 'my_module' (C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\my_module.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01munittest\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmy_module\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m my_function_to_test\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mTestMyFunctions\u001b[39;00m(unittest\u001b[38;5;241m.\u001b[39mTestCase):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_my_function\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;66;03m# Arrange\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'my_function_to_test' from 'my_module' (C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\my_module.py)"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "from my_module import my_function_to_test\n",
    "\n",
    "class TestMyFunctions(unittest.TestCase):\n",
    "    def test_my_function(self):\n",
    "        # Arrange\n",
    "        input_data = ...\n",
    "        expected_output = ...\n",
    "\n",
    "        # Act\n",
    "        result = my_function_to_test(input_data)\n",
    "\n",
    "        # Assert\n",
    "        self.assertEqual(result, expected_output)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb516146-3556-4e34-9565-21812c45c7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_data(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "def preprocess_data(data):\n",
    "    # Implement data preprocessing steps\n",
    "    return data_cleaned\n",
    "\n",
    "def split_data(data, test_size=0.2):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data['text'], data['label'], test_size=test_size, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2652a9d-f6f6-481e-80da-d136e42243ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class TextClassifier:\n",
    "    def __init__(self):\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "        self.model = LogisticRegression(max_iter=1000)\n",
    "    \n",
    "    def train(self, X_train, y_train):\n",
    "        X_train_tfidf = self.vectorizer.fit_transform(X_train)\n",
    "        self.model.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        X_test_tfidf = self.vectorizer.transform(X_test)\n",
    "        y_pred = self.model.predict(X_test_tfidf)\n",
    "        return accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22989de1-cc83-4cc4-b132-90f410631e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "class TopicModeler:\n",
    "    def __init__(self, n_topics=10):\n",
    "        self.n_topics = n_topics\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "        self.lda = LatentDirichletAllocation(n_components=n_topics, random_state=42)\n",
    "    \n",
    "    def fit_transform(self, data):\n",
    "        X_tfidf = self.vectorizer.fit_transform(data)\n",
    "        return self.lda.fit_transform(X_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95a8fbed-d178-43ae-a7dd-4adde7d178af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "class EventModeler:\n",
    "    def __init__(self, n_clusters=5):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    \n",
    "    def cluster_events(self, data):\n",
    "        return self.kmeans.fit_predict(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8cce74b-3372-4bd8-80b7-6830f3f9d2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "class MLFlowLogger:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def log_model(self, model, params, metrics):\n",
    "        with mlflow.start_run():\n",
    "            for key, value in params.items():\n",
    "                mlflow.log_param(key, value)\n",
    "            \n",
    "            for key, value in metrics.items():\n",
    "                mlflow.log_metric(key, value)\n",
    "            \n",
    "            mlflow.sklearn.log_model(model, \"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "571abb56-b0df-4132-bb77-52467ea1578f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data_processing, classification, topic_modeling, event_modeling, ml_engineering, mlflow_integration\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load and preprocess data\u001b[39;00m\n\u001b[0;32m      4\u001b[0m data \u001b[38;5;241m=\u001b[39m data_processing\u001b[38;5;241m.\u001b[39mload_data(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/news_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "from src import data_processing, classification, topic_modeling, event_modeling, ml_engineering, mlflow_integration\n",
    "\n",
    "# Load and preprocess data\n",
    "data = data_processing.load_data('data/news_data.csv')\n",
    "data_cleaned = data_processing.preprocess_data(data)\n",
    "X_train, X_test, y_train, y_test = data_processing.split_data(data_cleaned)\n",
    "\n",
    "# Train and evaluate classifier\n",
    "classifier = classification.TextClassifier()\n",
    "classifier.train(X_train, y_train)\n",
    "accuracy = classifier.evaluate(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Topic modeling\n",
    "topic_modeler = topic_modeling.TopicModeler()\n",
    "topic_distribution = topic_modeler.fit_transform(data_cleaned['text'])\n",
    "\n",
    "# Event modeling\n",
    "event_modeler = event_modeling.EventModeler()\n",
    "event_clusters = event_modeler.cluster_events(topic_distribution)\n",
    "\n",
    "# MLFlow integration\n",
    "mlflow_logger = mlflow_integration.MLFlowLogger()\n",
    "params = {'n_topics': 10}\n",
    "metrics = {'accuracy': accuracy}\n",
    "mlflow_logger.log_model(classifier.model, params, metrics)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4aaa486f-109f-42c0-9a99-59b836069330",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_processing\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdata_processing\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassification\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mclassification\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtopic_modeling\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtopic_modeling\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "import src.data_processing as data_processing\n",
    "import src.classification as classification\n",
    "import src.topic_modeling as topic_modeling\n",
    "import src.event_modeling as event_modeling\n",
    "import src.mlflow_integration as mlflow_integration\n",
    "\n",
    "# Load and preprocess data\n",
    "data = data_processing.load_data('data/news_data.csv')\n",
    "data_cleaned = data_processing.preprocess_data(data)\n",
    "X_train, X_test, y_train, y_test = data_processing.split_data(data_cleaned)\n",
    "\n",
    "# Train and evaluate classifier\n",
    "classifier = classification.TextClassifier()\n",
    "classifier.train(X_train, y_train)\n",
    "accuracy = classifier.evaluate(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Topic modeling\n",
    "topic_modeler = topic_modeling.TopicModeler()\n",
    "topic_distribution = topic_modeler.fit_transform(data_cleaned['text'])\n",
    "\n",
    "# Event modeling\n",
    "event_modeler = event_modeling.EventModeler()\n",
    "event_clusters = event_modeler.cluster_events(topic_distribution)\n",
    "\n",
    "# MLFlow integration\n",
    "mlflow_logger = mlflow_integration.MLFlowLogger()\n",
    "params = {'n_topics': 10}\n",
    "metrics = {'accuracy': accuracy}\n",
    "mlflow_logger.log_model(classifier.model, params, metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518c6a01-999e-4cc2-bde5-9300a973c942",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
